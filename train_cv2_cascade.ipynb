{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Curation and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is copied from other_detection_methods.ipynb for clarity. \n",
    "\n",
    "Trying to train our own cascade classifier using YT Faces dataset (setup by Ben). Here is the code used to parse the npz files and create a collection of positive examples with annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "positives_txt_path = os.path.join(\"data\", \"pos.txt\")\n",
    "positives_txt = open(positives_txt_path, \"w\")\n",
    "\n",
    "if not os.path.exists(\"data\",\"positives\"):\n",
    "    print(\"Creating data/positives directory!\")\n",
    "    os.makedirs(\"data\",\"positives\")\n",
    "\n",
    "for folder_idx in [1, 2, 3, 4]:\n",
    "\n",
    "    # You should have these directories after running Ben's setup code \n",
    "    # for yt_faces either using the corresponding flag in installData.py \n",
    "    path = os.path.join(\"data\", \"yt_faces\", f\"youtube_faces_with_keypoints_full_{folder_idx}\", \n",
    "                        f\"youtube_faces_with_keypoints_full_{folder_idx}\")\n",
    "    \n",
    "    with os.scandir(path) as entries:\n",
    "        for file in entries:\n",
    "            # print(file.name)\n",
    "            file_path = os.path.join(path, file.name)\n",
    "            arr = np.load(file_path)\n",
    "            \n",
    "            # Each loaded npz file contains multiple samples (eg, 79 in Aaron_Eckhart_0.npz) in the last dimension.\n",
    "            color_images = arr[\"colorImages\"]    # Shape: (231, 237, 3, 79)\n",
    "            bounding_boxes = arr[\"boundingBox\"]    # Shape: (4, 2, 79)\n",
    "            \n",
    "            num_samples = color_images.shape[-1]\n",
    "            # print(\"Number of samples in file:\", num_samples)\n",
    "\n",
    "            # Iterate over each sample\n",
    "            for sample_idx in range(num_samples):\n",
    "                # Skip 98% of examples since there are ~260k \n",
    "                if random.random() <= 0.98:\n",
    "                    continue \n",
    "                count += 1 \n",
    "                image_frame = color_images[:, :, :, sample_idx]  # (231, 237, 3)\n",
    "                image_frame = cv2.cvtColor(image_frame, cv2.COLOR_RGB2BGR)\n",
    "                bbox = bounding_boxes[:, :, sample_idx]           # (4, 2)\n",
    "                # print(f\"Sample index: {sample_idx} \\nBounding Box:\\n {bbox}\")\n",
    "                \n",
    "                # Resize image to 224x224\n",
    "                original_height, original_width = image_frame.shape[:2]\n",
    "                image_frame = cv2.resize(image_frame, (224, 224))\n",
    "\n",
    "                # Using x,y,w,h here as instructed by the training cascade classifier docs. \n",
    "                x = int(np.min(bbox[:, 0]))\n",
    "                y = int(np.min(bbox[:, 1]))\n",
    "                w = int(np.max(bbox[:, 0]) - x)\n",
    "                h = int(np.max(bbox[:, 1]) - y)\n",
    "\n",
    "                # Rescale bounding box coordinates\n",
    "                x = int(x * (224 / original_width))\n",
    "                y = int(y * (224 / original_height))\n",
    "                w = int(w * (224 / original_width))\n",
    "                h = int(h * (224 / original_height))\n",
    "\n",
    "                img_filename = f\"img{count}.jpg\"\n",
    "                img_filepath = os.path.join(\"data\", \"positives\", img_filename)\n",
    "                cv2.imwrite(img_filepath, image_frame)\n",
    "                \n",
    "                \"\"\" VISUALIZATION ONLY \"\"\"\n",
    "                # cv2.rectangle() expects x1,y1,x2,y2 (top left and bottom right coordinates)\n",
    "                # cv2.rectangle(image_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                # plt.imshow(cv2.cvtColor(image_frame, cv2.COLOR_BGR2RGB))\n",
    "                # plt.axis(\"off\")\n",
    "                # plt.show()\n",
    "\n",
    "                positives_txt.write(f\"data/positives/{img_filename} 1 {x} {y} {w} {h}\\n\")\n",
    "        \n",
    "positives_txt.close()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = os.path.join(\"data\",\"pos.txt\")\n",
    "output_file = os.path.join(\"data\",\"pos_subset.txt\")\n",
    "\n",
    "with open(input_file, \"r\") as f1:\n",
    "    lines = f1.readlines()\n",
    "\n",
    "# Sample a small number of positives, so that we can test if the training even works\n",
    "selected_lines = random.sample(lines, 1500)\n",
    "\n",
    "with open(output_file, \"w\") as f2:\n",
    "    f2.writelines(selected_lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create negative examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_random_images_and_write_to_negative_txt(src_dir, dest_dir, num_files=2000):\n",
    "\n",
    "    negatives_txt_path = os.path.join(\"data\", \"neg.txt\")\n",
    "    negatives_txt = open(negatives_txt_path, \"a\")\n",
    "\n",
    "    all_files = [f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))]\n",
    "    \n",
    "    selected_files = random.sample(all_files, min(num_files, len(all_files)))\n",
    "    \n",
    "    for file in selected_files:\n",
    "        shutil.copy(os.path.join(src_dir, file), os.path.join(dest_dir, file))\n",
    "        negatives_txt.write(f\"{dest_dir}\\\\{file}\\n\")   \n",
    "\n",
    "    print(f\"Copied {len(selected_files)} files from {src_dir} to {dest_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_dir = os.path.join(\"data\",\"negatives\")\n",
    "\"\"\"\n",
    "This data was taken from: https://www.kaggle.com/datasets/mikhailma/house-rooms-streets-image-dataset/data\"\n",
    "Simply download and extract into /data.\n",
    "\n",
    "My reasoning for choosing housing/street data as negative examples was because a) these are higher quality than the CIFAR-10 and caltech negative examples, and b) I think faces are more likely to be seen with these backgrounds so maybe it might help for the negative examples to be indicative of actual backgrounds?\n",
    "\"\"\"\n",
    "kaggle_street_dir = os.path.join(\"data\", \"kaggle_room_street_data\", \"street_data\")\n",
    "kaggle_house_dir = os.path.join(\"data\", \"kaggle_room_street_data\", \"house_data\")\n",
    "\n",
    "if not os.path.exists(negatives_dir):\n",
    "    print(\"Creating data/negatives directory!\")\n",
    "    os.makedirs(negatives_dir)\n",
    "\n",
    "pick_random_images_and_write_to_negative_txt(kaggle_house_dir, negatives_dir)\n",
    "pick_random_images_and_write_to_negative_txt(kaggle_street_dir, negatives_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following commands should be run from the root directory of the repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a vector file using \n",
    "\n",
    "```bash\n",
    "opencv_createsamples.exe -info data/pos_subset.txt -w 64 -h 64 -num 3000 -vec data/pos.vec\n",
    "```\n",
    "> This tool is part of a collection of tools that can be installed from https://sourceforge.net/projects/opencvlibrary/files/3.4.16/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can train the classifier using\n",
    "\n",
    "```bash\n",
    "opencv_traincascade.exe -data cascade/ -vec data/pos.vec -bg data/neg.txt -w 64 -h 64 -numPos 1000 -numNeg 2000 -numStages 10 -minHitRate 0.99\n",
    "```\n",
    "> This tool is also part of the same collection of tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error message:\n",
    "```sh\n",
    "PS C:\\Users\\syeda\\OneDrive\\Desktop\\4th Year\\COSC444\\face-recognition> C:\\Users\\syeda\\Downloads\\opencv\\build\\x64\\vc15\\bin\\opencv_traincascade.exe -data cascade/ -vec data/pos.vec -bg data/neg.txt -w 64 -h 64 -numPos 1000 -numNeg 2000 -numStages 10 -minHitRate 0.95\n",
    "PARAMETERS:                                                                                                 7783963ff\n",
    "cascadeDirName: cascade/\n",
    "vecFileName: data/pos.vec\n",
    "bgFileName: data/neg.txt\n",
    "numPos: 1000\n",
    "numNeg: 2000\n",
    "numStages: 10\n",
    "precalcValBufSize[Mb] : 1024\n",
    "precalcIdxBufSize[Mb] : 1024\n",
    "stageType: BOOST\n",
    "featureType: HAAR\n",
    "sampleWidth: 64\n",
    "sampleHeight: 64\n",
    "boostType: GAB\n",
    "minHitRate: 0.95\n",
    "maxFalseAlarmRate: 0.5\n",
    "weightTrimRate: 0.95\n",
    "maxDepth: 1\n",
    "maxWeakCount: 100\n",
    "mode: BASIC\n",
    "Number of unique features given windowSize [64,64] : 8103936\n",
    "\n",
    "===== TRAINING 0-stage =====\n",
    "<BEGIN\n",
    "POS count : consumed   1000 : 1000\n",
    "Train dataset for temp stage can not be filled. Branch training terminated.\n",
    "Cascade classifier can't be trained. Check the used training parameters.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
