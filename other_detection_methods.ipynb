{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haar Cascades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the popular [Viola-Jones](https://link.springer.com/article/10.1023/B:VISI.0000013087.49260.fb) framework for object detection. They proposed using Haar filters (two-valued,  rectangular masks), efficiently computed using \"integral\" images (where each pixel value is replaced with the sum of all the pixel values above and to the left of it). Something like a 2D, discrete CDF in probability theory. They also proposed using a \"cascade\" of weak classifiers to improve performance.\n",
    "\n",
    "OpenCV offers an implementation of this under the \"CascadeClassifier\" class, along with pretrained classifiers for face detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_haar(image_path, output_path): \n",
    "    # Path to preset face detection cascade file that come with OpenCV out of the box. Some other cascade files can be found at venv/Lib/site-packages/cv2/data\n",
    "    face_detection_cascade_file = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "    face_cascade = cv2.CascadeClassifier(face_detection_cascade_file)     \n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    cv2.imshow(\"Base image\", image)\n",
    "    faces_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Parameters for detectMultiScale taken from https://stackoverflow.com/questions/20801015/recommended-values-for-opencv-detectmultiscale-parameters \n",
    "    # along with some experiments on the sample image\n",
    "    faces = face_cascade.detectMultiScale(faces_gray, scaleFactor = 1.2, minNeighbors = 4)      # these values can be changed as needed \n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imwrite(output_path, image)\n",
    "    cv2.imshow(\"Detected faces (Haar Cascade)\", image)\n",
    "    print(\"Close windows or press key to exit.\")\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_from_camera():\n",
    "\n",
    "    face_detection_cascade_file = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "    face_cascade = cv2.CascadeClassifier(face_detection_cascade_file) \n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not access the webcam.\")\n",
    "        return \"Error\"\n",
    "\n",
    "    print(\"Press 'q' to capture an image and 'e' to exit.\")\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame.\")\n",
    "                break\n",
    "\n",
    "            cv2.imshow(\"Camera Feed\", frame)\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord(\"q\"):\n",
    "                gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                faces = face_cascade.detectMultiScale(gray_img, scaleFactor = 1.2, minNeighbors = 4)      # these values can be changed as needed\n",
    "\n",
    "                result = \"Non-face\"\n",
    "                color = (0, 0, 255) \n",
    "\n",
    "                if len(faces) > 0:\n",
    "                    result = \"Face\"\n",
    "                    color = (0, 255, 0)\n",
    "                    \n",
    "                    for (x, y, w, h) in faces:\n",
    "                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    result,\n",
    "                    (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_AA,\n",
    "                )\n",
    "                cv2.imshow(\"Captured Image\", frame)\n",
    "\n",
    "            if key == ord(\"e\"):\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_faces_haar(\"samples/face_detection/solvay_color.jpg\", \"samples/face_detection/solvay_detected_haar.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_face_from_camera()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works well on the sample image, but the camera feed performance is terrible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should experiment with these \n",
    "ORIENTATIONS = 8\n",
    "PIXELS_PER_CELL = (4,4)\n",
    "CELLS_PER_BLOCK = (2,2)\n",
    "IMAGE_SHAPE = (128,128)     # not 64x128 as in the paper because that was for people detection. We can use square windows for our use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACE_FOLDER = os.path.join(\"data\", \"face\", \"Face\")\n",
    "NON_FACE_FOLDER = os.path.join(\"data\", \"other\", \"Other\")\n",
    "MAX_IMAGES = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "# These 3 are needed if we didnt use cv2\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from skimage import data, exposure, color\n",
    "\n",
    "# image = asarray(Image.open(\"samples/face_detection/solvay_color.jpg\"))\n",
    "\n",
    "image = cv2.imread(\"samples/face_detection/solvay_color.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, IMAGE_SHAPE)  # Resize to 64x128\n",
    "\n",
    "fd, hog_image = hog(\n",
    "    image,\n",
    "    orientations=ORIENTATIONS,\n",
    "    pixels_per_cell=PIXELS_PER_CELL,\n",
    "    cells_per_block=CELLS_PER_BLOCK,\n",
    "    visualize=True,\n",
    "    feature_vector=True\n",
    "    # channel_axis=-1,\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "\n",
    "ax1.axis('off')\n",
    "ax1.imshow(image, cmap=plt.cm.gray)\n",
    "ax1.set_title('Input image')\n",
    "\n",
    "# Rescale histogram for better display\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "ax2.axis('off')\n",
    "ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax2.set_title('Histogram of Oriented Gradients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(image,\n",
    "                         orientations=ORIENTATIONS,\n",
    "                         pixels_per_cell=PIXELS_PER_CELL,\n",
    "                         cells_per_block=CELLS_PER_BLOCK,\n",
    "                         visualize=False):\n",
    "    \"\"\"\n",
    "    Compute HOG features for a given grayscale image.\n",
    "    The image should be resized to the fixed detection window size.\n",
    "    \"\"\"\n",
    "\n",
    "    image = cv2.resize(image, IMAGE_SHAPE)\n",
    "\n",
    "    if visualize: \n",
    "        features, hog_image = hog(image,\n",
    "                    orientations=orientations,\n",
    "                    pixels_per_cell=pixels_per_cell,\n",
    "                    cells_per_block=cells_per_block,\n",
    "                    block_norm='L2-Hys',\n",
    "                    transform_sqrt=True,\n",
    "                    feature_vector=True,\n",
    "                    visualize=True)\n",
    "        return features, hog_image\n",
    "    \n",
    "    else:\n",
    "        features = hog(image,\n",
    "                    orientations=orientations,\n",
    "                    pixels_per_cell=pixels_per_cell,\n",
    "                    cells_per_block=cells_per_block,\n",
    "                    block_norm='L2-Hys',\n",
    "                    transform_sqrt=True,\n",
    "                    feature_vector=True)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vectors_from_folder(folder, label, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "        Adapted from Ghaith's function in baseline.ipynb \n",
    "\n",
    "        kwargs could contain these keys: \n",
    "            - 'max_images': int value, limiting num images to add to the dataset\n",
    "            - HOG hyperparameters: 'orientations' (int), 'pixels_per_cell', 'cells_per_block' and 'img_size'\n",
    "    \n",
    "        Returns a tuple containing 2 elements: \n",
    "            i)  a list of feature vectors (each feature vector is a list)\n",
    "            ii) a list containing the passed in label repeated max_images times \n",
    "                i.e. a list of all 1's if we choose positive examples folder (i.e. data/face/Face folder) or all 0's for negative examples  \n",
    "    \"\"\"\n",
    "    images_paths = [f for f in os.listdir(folder)]\n",
    "    random.shuffle(images_paths)\n",
    "\n",
    "    # Get kwargs, should just default to constants defined earlier\n",
    "    max_images      = kwargs.get('max_images', None)\n",
    "    orientations    = kwargs.get('orientations', ORIENTATIONS)\n",
    "    pixels_per_cell = kwargs.get('pixels_per_cell', PIXELS_PER_CELL)\n",
    "    cells_per_block = kwargs.get('cells_per_block', CELLS_PER_BLOCK)\n",
    "    img_size        = kwargs.get('img_size', IMAGE_SHAPE)\n",
    "\n",
    "    if max_images is not None:\n",
    "        images_paths = images_paths[:max_images]\n",
    "\n",
    "    features = []\n",
    "    paths = []\n",
    "    for image_path in images_paths:\n",
    "        full_image_path = os.path.join(folder, image_path)\n",
    "        img = cv2.imread(full_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, img_size)\n",
    "            feature_vec = extract_hog_features(img,\n",
    "                                            orientations=orientations,\n",
    "                                            pixels_per_cell=pixels_per_cell,\n",
    "                                            cells_per_block=cells_per_block)\n",
    "            features.append(feature_vec)\n",
    "            paths.append(full_image_path)\n",
    "\n",
    "    return np.array(features), np.full(len(features), label), paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_vectors, face_labels, face_paths = get_feature_vectors_from_folder(\n",
    "    FACE_FOLDER, label=1, max_images=MAX_IMAGES\n",
    ")\n",
    "\n",
    "non_face_vectors, non_face_labels, non_face_paths = get_feature_vectors_from_folder(\n",
    "    NON_FACE_FOLDER, label=0, max_images=len(face_vectors)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took around 40 seconds on my machine for 2000 face and 2000 non-face images (around 100 images/sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.vstack((face_vectors, non_face_vectors))   \n",
    "y = np.hstack((face_labels, non_face_labels))\n",
    "paths = face_paths + non_face_paths\n",
    "\n",
    "# Manually shuffling so we can keep track of the list of image_paths as well\n",
    "shuffled_indices = np.random.permutation(len(X))\n",
    "\n",
    "X = X[shuffled_indices]\n",
    "y = y[shuffled_indices]\n",
    "shuffled_paths = [paths[ind] for ind in shuffled_indices]\n",
    "\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train = X[:split_index]\n",
    "X_test  = X[split_index:]\n",
    "y_train = y[:split_index]\n",
    "y_test  = y[split_index:]\n",
    "shuffled_paths_train = shuffled_paths[:split_index]\n",
    "shuffled_paths_test = shuffled_paths[split_index:]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, shuffle=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8100 dimensional feature vectors\n",
    "print(\"Training samples:\", X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(shuffled_paths_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel=\"rbf\", random_state=42)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "y_hat = svm.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_hat)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_hat)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=np.unique(y_test),\n",
    "    yticklabels=np.unique(y_test),\n",
    ")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_indices = [i for i in range(len(y_test)) if y_hat[i] != y_test[i]]\n",
    "\n",
    "random.seed(None)\n",
    "random.shuffle(incorrect_indices)\n",
    "random.seed(42)\n",
    "\n",
    "num_to_display = min(len(incorrect_indices), 5)\n",
    "plt.figure(figsize=(15, num_to_display))\n",
    "\n",
    "for i in range(num_to_display):\n",
    "    idx = incorrect_indices[i]\n",
    "\n",
    "    true_label = \"Face\" if y_test[idx] == 1 else \"Non-Face\"\n",
    "    predicted_label = \"Face\" if y_hat[idx] == 1 else \"Non-Face\"\n",
    "    img = cv2.imread(shuffled_paths_test[idx], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    plt.subplot(1, num_to_display, i + 1)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(f\"True: {true_label}, Pred: {predicted_label}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image_from_camera():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not access the webcam.\")\n",
    "        return \"Error\"\n",
    "\n",
    "    print(\"Press 'q' to capture an image and 'e' to exit.\")\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame.\")\n",
    "                break\n",
    "\n",
    "            cv2.imshow(\"Camera Feed\", frame)\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord(\"q\"):\n",
    "                gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                gray_img = cv2.resize(gray_img, IMAGE_SHAPE)\n",
    "\n",
    "                feature_vec = extract_hog_features(gray_img,\n",
    "                                                orientations=ORIENTATIONS,\n",
    "                                                pixels_per_cell=PIXELS_PER_CELL,\n",
    "                                                cells_per_block=CELLS_PER_BLOCK)\n",
    "\n",
    "                prediction = svm.predict(feature_vec.reshape(1,-1))\n",
    "                result = \"Face\" if prediction == 1 else \"Non-Face\"\n",
    "                color = (0, 255, 0) if prediction == 1 else (0, 0, 255)\n",
    "\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    result,\n",
    "                    (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1,\n",
    "                    color,\n",
    "                    2,\n",
    "                    cv2.LINE_AA,\n",
    "                )\n",
    "\n",
    "                cv2.imshow(\"Captured Image\", gray_img)\n",
    "                cv2.imshow(\"Prediction\", frame)\n",
    "\n",
    "            if key == ord(\"e\"):\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image_from_camera()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TERRIBLE camera performance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
