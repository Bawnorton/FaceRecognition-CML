{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "719fee61141b8ddd",
   "metadata": {},
   "source": [
    "# HOG + SVM\n",
    "\n",
    "Using YT Faces dataset and other dataset to train a SVM model with HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ef6cba57a97a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from yt_faces import YTFacesDataset\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_FACES_DATASET = YTFacesDataset(os.path.join(\"data\", \"yt_faces\"))\n",
    "NON_FACE_DATASET_PATH = os.path.join(\"data\", \"natural_images\", \"Other\")\n",
    "\n",
    "YT_FACES_DATASET.load(frames_per_recording=10) # ~4 mins to load faces, ~8 mins to pre-process and load splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221bfa8dc1069c91",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1204cd9909a7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIENTATIONS = 9\n",
    "PIXELS_PER_CELL = (4, 4)\n",
    "CELLS_PER_BLOCK = (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c0bcf1c8398666",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"samples/face_detection/solvay_color.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "res = image.shape[:2]\n",
    "target_res = [\n",
    "    ((res[0] + 15) // 16) * 16,\n",
    "    ((res[1] + 15) // 16) * 16\n",
    "]\n",
    "pad_x = (target_res[0] - res[0]) // 2\n",
    "pad_y = (target_res[1] - res[1]) // 2\n",
    "image = cv2.copyMakeBorder(image, pad_x, pad_x, pad_y, pad_y, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "\n",
    "fd, hog_image = hog(\n",
    "    image,\n",
    "    orientations=ORIENTATIONS,\n",
    "    pixels_per_cell=PIXELS_PER_CELL,\n",
    "    cells_per_block=CELLS_PER_BLOCK,\n",
    "    visualize=True,\n",
    "    feature_vector=True,\n",
    ")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "\n",
    "ax1.axis('off')\n",
    "ax1.imshow(image, cmap=plt.cm.gray)\n",
    "ax1.set_title('Input image')\n",
    "\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "\n",
    "ax2.axis('off')\n",
    "ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax2.set_title('Histogram of Oriented Gradients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268181ce097d4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(image,\n",
    "                         orientations=ORIENTATIONS,\n",
    "                         pixels_per_cell=PIXELS_PER_CELL,\n",
    "                         cells_per_block=CELLS_PER_BLOCK,\n",
    "                         visualize=False):\n",
    "\n",
    "    if visualize:\n",
    "        features, hog_image = hog(image,\n",
    "                    orientations=orientations,\n",
    "                    pixels_per_cell=pixels_per_cell,\n",
    "                    cells_per_block=cells_per_block,\n",
    "                    block_norm='L2-Hys',\n",
    "                    transform_sqrt=True,\n",
    "                    feature_vector=True,\n",
    "                    visualize=True)\n",
    "        return features, hog_image\n",
    "\n",
    "    else:\n",
    "        features = hog(image,\n",
    "                    orientations=orientations,\n",
    "                    pixels_per_cell=pixels_per_cell,\n",
    "                    cells_per_block=cells_per_block,\n",
    "                    block_norm='L2-Hys',\n",
    "                    transform_sqrt=True,\n",
    "                    feature_vector=True)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b99b2f39d8602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vectors_from_folder(folder, label, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "        Adapted from Ghaith's function in baseline.ipynb\n",
    "\n",
    "        kwargs could contain these keys:\n",
    "            - 'max_images': int value, limiting num images to add to the dataset\n",
    "            - HOG hyperparameters: 'orientations' (int), 'pixels_per_cell', 'cells_per_block' and 'img_size'\n",
    "\n",
    "        Returns a tuple containing 2 elements:\n",
    "            i)  a list of feature vectors (each feature vector is a list)\n",
    "            ii) a list containing the passed in label repeated max_images times\n",
    "                i.e. a list of all 1's if we choose positive examples folder (i.e. data/face/Face folder) or all 0's for negative examples\n",
    "    \"\"\"\n",
    "    images_paths = [f for f in os.listdir(folder)]\n",
    "    random.shuffle(images_paths)\n",
    "\n",
    "    # Get kwargs, should just default to constants defined earlier\n",
    "    max_images      = kwargs.get('max_images', None)\n",
    "    orientations    = kwargs.get('orientations', ORIENTATIONS)\n",
    "    pixels_per_cell = kwargs.get('pixels_per_cell', PIXELS_PER_CELL)\n",
    "    cells_per_block = kwargs.get('cells_per_block', CELLS_PER_BLOCK)\n",
    "\n",
    "    if max_images is not None:\n",
    "        images_paths = images_paths[:max_images]\n",
    "\n",
    "    features = []\n",
    "    paths = []\n",
    "    for image_path in images_paths:\n",
    "        full_image_path = os.path.join(folder, image_path)\n",
    "        img = cv2.imread(full_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (480, 480))\n",
    "            feature_vec = extract_hog_features(img,\n",
    "                                            orientations=orientations,\n",
    "                                            pixels_per_cell=pixels_per_cell,\n",
    "                                            cells_per_block=cells_per_block)\n",
    "            features.append(feature_vec)\n",
    "            paths.append(full_image_path)\n",
    "\n",
    "    return np.array(features), np.full(len(features), label), paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3891480c6d2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = YT_FACES_DATASET.get_splits()\n",
    "\n",
    "face_vectors, face_labels, face_paths = get_feature_vectors_from_folder(\n",
    "    splits[\"train\"], label=1, max_images=2000\n",
    ")\n",
    "\n",
    "non_face_vectors, non_face_labels, non_face_paths = get_feature_vectors_from_folder(\n",
    "    NON_FACE_DATASET_PATH, label=0, max_images=len(face_vectors)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd17cfc16f8caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((face_vectors, non_face_vectors))\n",
    "Y = np.hstack((face_labels, non_face_labels))\n",
    "\n",
    "paths = face_paths + non_face_paths\n",
    "\n",
    "# Manually shuffling so we can keep track of the list of image_paths as well\n",
    "shuffled_indices = np.random.permutation(len(X))\n",
    "\n",
    "X = X[shuffled_indices]\n",
    "Y = Y[shuffled_indices]\n",
    "shuffled_paths = [paths[ind] for ind in shuffled_indices]\n",
    "\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train = X[:split_index]\n",
    "X_test  = X[split_index:]\n",
    "Y_train = Y[:split_index]\n",
    "Y_test  = Y[split_index:]\n",
    "shuffled_paths_train = shuffled_paths[:split_index]\n",
    "shuffled_paths_test = shuffled_paths[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb571769856fe83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=\"rbf\", random_state=42)\n",
    "svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c7424bde1c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = svm.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, Y_hat)}\")\n",
    "print(\"Classification Report:\\n\", classification_report(Y_test, Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ebe68feea78e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(Y_test, Y_hat)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=np.unique(Y_test),\n",
    "    yticklabels=np.unique(Y_test),\n",
    ")\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332b812c9cd6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_indices = [i for i in range(len(Y_test)) if Y_hat[i] != Y_test[i]]\n",
    "\n",
    "random.seed(None)\n",
    "random.shuffle(incorrect_indices)\n",
    "random.seed(42)\n",
    "\n",
    "num_to_display = min(len(incorrect_indices), 5)\n",
    "plt.figure(figsize=(15, num_to_display))\n",
    "\n",
    "for i in range(num_to_display):\n",
    "    idx = incorrect_indices[i]\n",
    "\n",
    "    true_label = \"Face\" if Y_test[idx] == 1 else \"Non-Face\"\n",
    "    predicted_label = \"Face\" if Y_hat[idx] == 1 else \"Non-Face\"\n",
    "    img = cv2.imread(shuffled_paths_test[idx], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    plt.subplot(1, num_to_display, i + 1)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(f\"True: {true_label}, Pred: {predicted_label}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b1829c4caff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid(image, scale=1.5, min_size=(128, 128)):\n",
    "    yield image\n",
    "    while True:\n",
    "        w = int(image.shape[1] / scale)\n",
    "        image = cv2.resize(image, (w, int(image.shape[0] / scale)))\n",
    "        if image.shape[0] < min_size[1] or image.shape[1] < min_size[0]:\n",
    "            break\n",
    "        yield image\n",
    "\n",
    "def sliding_window(image, step_size, window_size):\n",
    "    for y in range(0, image.shape[0] - window_size[1], step_size):\n",
    "        for x in range(0, image.shape[1] - window_size[0], step_size):\n",
    "            yield x, y, image[y:y + window_size[1], x:x + window_size[0]]\n",
    "\n",
    "def resize_and_pad(image, target_size):\n",
    "    h, w = image.shape[:2]\n",
    "    target_w, target_h = target_size\n",
    "    scale = min(target_w / w, target_h / h)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    resized_img = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    result = np.zeros((target_h, target_w), dtype=np.uint8)\n",
    "    x_offset = (target_w - new_w) // 2\n",
    "    y_offset = (target_h - new_h) // 2\n",
    "    result[y_offset:y_offset + new_h, x_offset:x_offset + new_w] = resized_img\n",
    "\n",
    "    return result\n",
    "\n",
    "def live_face_detector():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not access the webcam.\")\n",
    "        return\n",
    "\n",
    "    print(\"Press q to capture the frame, e to exit the program.\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            cv2.imshow(\"Camera Feed\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                gray = resize_and_pad(gray, (480, 480))\n",
    "                feature_vec, histogram = extract_hog_features(gray, visualize=True)\n",
    "                decision = svm.decision_function(feature_vec.reshape(1, -1))\n",
    "                result = \"Face\" if decision > 0 else \"Non-Face\"\n",
    "                print(f\"Prediction: {result}, Decision: {decision[0]}\")\n",
    "                color = (0, 255, 0) if result == \"Face\" else (0, 0, 255)\n",
    "                cv2.putText(frame, result, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "                cv2.imshow(\"Captured Image\", gray)\n",
    "                cv2.imshow(\"HOG\", histogram)\n",
    "                cv2.imshow(\"Prediction\", frame)\n",
    "            elif key == ord('e'):\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554b7799801c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "live_face_detector()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
