{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of SIFT and SIFT-SVM (BoVW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_histogram = 100\n",
    "min_image_num = 10\n",
    "min_sift_matches = 20\n",
    "training_set_size = 10\n",
    "training_image_num = 5\n",
    "num_misclassified_to_show = 5\n",
    "lowes_sift_compare_ratio = 0.75\n",
    "\n",
    "\n",
    "base_folder = \"../data/face/lfw-deepfunneled/lfw-deepfunneled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for person in os.listdir(base_folder):\n",
    "    person_dir = os.path.join(base_folder, person)\n",
    "    if os.path.isdir(person_dir):\n",
    "        images = []\n",
    "        for img_name in os.listdir(person_dir):\n",
    "            img_path = os.path.join(person_dir, img_name)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "        if len(images) >= min_image_num:\n",
    "            data[person] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "people_names = list(data.keys())\n",
    "\n",
    "for person, images in data.items():\n",
    "    train_images = []\n",
    "    test_images = []\n",
    "    random.shuffle(images)\n",
    "\n",
    "    train_images.extend(images[:training_image_num])\n",
    "    test_images.extend(images[training_image_num:])\n",
    "    train_labels = [person] * training_image_num\n",
    "    test_labels = [person] * (len(images) - training_image_num)\n",
    "\n",
    "    other_people = random.sample(\n",
    "        [p for p in people_names if p != person],\n",
    "        2 * (training_set_size - training_image_num),\n",
    "    )\n",
    "\n",
    "    for i, other_person in enumerate(other_people):\n",
    "        chosen_image = random.sample(data[other_person], 1)[0]\n",
    "        if i % 2 == 0:\n",
    "            train_images.append(chosen_image)\n",
    "            train_labels.append(\"Unknown\")\n",
    "        else:\n",
    "            test_images.append(chosen_image)\n",
    "            test_labels.append(\"Unknown\")\n",
    "\n",
    "    x_train.append(train_images)\n",
    "    x_test.append(test_images)\n",
    "    y_train.append(train_labels)\n",
    "    y_test.append(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "bf = cv2.BFMatcher()\n",
    "\n",
    "\n",
    "def extract_sift_features(image_list):\n",
    "    keypoints_list = []\n",
    "    descriptors_list = []\n",
    "\n",
    "    for img in image_list:\n",
    "        keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "\n",
    "        keypoints_list.append(keypoints)\n",
    "        descriptors_list.append(descriptors)\n",
    "\n",
    "    return keypoints_list, descriptors_list\n",
    "\n",
    "\n",
    "def compare_sift_features(descriptors_1, descriptors_2):\n",
    "    descriptors_1 = np.array(descriptors_1).astype(\"float32\")\n",
    "    descriptors_2 = np.array(descriptors_2).astype(\"float32\")\n",
    "\n",
    "    good = []\n",
    "    matches = bf.knnMatch(descriptors_1, descriptors_2, k=2)\n",
    "    for m, n in matches:\n",
    "        if m.distance < lowes_sift_compare_ratio * n.distance:\n",
    "            good.append([m])\n",
    "    return len(good) > min_sift_matches, good\n",
    "\n",
    "\n",
    "def create_bow_histogram(descriptors, kmeans):\n",
    "    if descriptors is None or len(descriptors) == 0:\n",
    "        return np.zeros(kmeans.cluster_centers_.shape[0])\n",
    "\n",
    "    cluster_indices = kmeans.predict(descriptors)\n",
    "    hist, _ = np.histogram(\n",
    "        cluster_indices,\n",
    "        bins=np.arange(kmeans.n_clusters + 1),\n",
    "        range=(0, kmeans.n_clusters),\n",
    "    )\n",
    "\n",
    "    return hist\n",
    "\n",
    "\n",
    "def train_svm(descriptors_list, label_list):\n",
    "    all_descriptors = np.vstack(descriptors_list)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=k_histogram)\n",
    "    kmeans.fit(all_descriptors)\n",
    "\n",
    "    histograms = []\n",
    "    for descriptors in descriptors_list:\n",
    "        hist = create_bow_histogram(descriptors, kmeans)\n",
    "        histograms.append(hist)\n",
    "\n",
    "    svm = SVC(kernel=\"linear\")\n",
    "    svm.fit(histograms, label_list)\n",
    "\n",
    "    return svm, kmeans\n",
    "\n",
    "\n",
    "def predict_with_svm(svm, kmeans, new_image):\n",
    "    _, new_descriptors = sift.detectAndCompute(new_image, None)\n",
    "    if new_descriptors is None or len(new_descriptors) == 0:\n",
    "        return None\n",
    "\n",
    "    new_hist = create_bow_histogram(new_descriptors, kmeans)\n",
    "    prediction = svm.predict([new_hist])\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(true_labels, predicted_labels):\n",
    "    precision = precision_score(\n",
    "        true_labels,\n",
    "        predicted_labels,\n",
    "        average=\"weighted\",\n",
    "        labels=np.unique(true_labels),\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    recall = recall_score(\n",
    "        true_labels,\n",
    "        predicted_labels,\n",
    "        average=\"weighted\",\n",
    "        labels=np.unique(true_labels),\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    return precision, recall, accuracy\n",
    "\n",
    "\n",
    "def track_misclassifications(test_images, true_labels, predicted_labels):\n",
    "    misclassified_images = []\n",
    "    misclassified_true_labels = []\n",
    "    misclassified_pred_labels = []\n",
    "\n",
    "    true_labels = np.array(true_labels)\n",
    "    misclassified_indices = np.where(predicted_labels != true_labels)[0]\n",
    "\n",
    "    for idx in misclassified_indices:\n",
    "        misclassified_images.append(test_images[idx])\n",
    "        misclassified_true_labels.append(true_labels[idx])\n",
    "        misclassified_pred_labels.append(predicted_labels[idx])\n",
    "\n",
    "    return misclassified_images, misclassified_true_labels, misclassified_pred_labels\n",
    "\n",
    "\n",
    "def visualize_misclassifications(\n",
    "    title, misclassified_images, misclassified_true_labels, misclassified_pred_labels\n",
    "):\n",
    "    misclassified_indices_sample = random.sample(\n",
    "        range(len(misclassified_images)),\n",
    "        min(num_misclassified_to_show, len(misclassified_images)),\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "\n",
    "    for idx, misclassified_idx in enumerate(misclassified_indices_sample):\n",
    "        image = misclassified_images[misclassified_idx]\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        true_label = misclassified_true_labels[misclassified_idx]\n",
    "        predicted_label = misclassified_pred_labels[misclassified_idx]\n",
    "\n",
    "        plt.subplot(1, num_misclassified_to_show, idx + 1)\n",
    "        plt.imshow(image_rgb)\n",
    "        plt.title(f\"True: {true_label}\\nPred: {predicted_label}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(title, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_metrics(title, all_precision, all_recall, all_accuracy):\n",
    "    average_precision = np.mean(all_precision)\n",
    "    average_recall = np.mean(all_recall)\n",
    "    average_accuracy = np.mean(all_accuracy)\n",
    "\n",
    "    print(title)\n",
    "    print(f\"Average Precision: {average_precision}\")\n",
    "    print(f\"Average Recall: {average_recall}\")\n",
    "    print(f\"Average Accuracy: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bovw():\n",
    "    all_precision = []\n",
    "    all_recall = []\n",
    "    all_accuracy = []\n",
    "\n",
    "    misclassified_images = []\n",
    "    misclassified_true_labels = []\n",
    "    misclassified_pred_labels = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        training_set_person_i = x_train[i]\n",
    "        training_label_set_person_i = y_train[i]\n",
    "        testing_set_person_i = x_test[i]\n",
    "        testing_label_set_person_i = y_test[i]\n",
    "\n",
    "        _, train_desc = extract_sift_features(training_set_person_i)\n",
    "        trained_svm, kmeans = train_svm(train_desc, training_label_set_person_i)\n",
    "        test_predictions = [\n",
    "            predict_with_svm(trained_svm, kmeans, xi) for xi in testing_set_person_i\n",
    "        ]\n",
    "\n",
    "        precision, recall, accuracy = calculate_metrics(\n",
    "            testing_label_set_person_i, test_predictions\n",
    "        )\n",
    "\n",
    "        all_precision.append(precision)\n",
    "        all_recall.append(recall)\n",
    "        all_accuracy.append(accuracy)\n",
    "\n",
    "        (\n",
    "            misclassified_batch_images,\n",
    "            misclassified_batch_true_labels,\n",
    "            misclassified_batch_pred_labels,\n",
    "        ) = track_misclassifications(\n",
    "            testing_set_person_i,\n",
    "            testing_label_set_person_i,\n",
    "            test_predictions,\n",
    "        )\n",
    "\n",
    "        misclassified_images.extend(misclassified_batch_images)\n",
    "        misclassified_true_labels.extend(misclassified_batch_true_labels)\n",
    "        misclassified_pred_labels.extend(misclassified_batch_pred_labels)\n",
    "\n",
    "    return (all_precision, all_recall, all_accuracy), (\n",
    "        misclassified_images,\n",
    "        misclassified_true_labels,\n",
    "        misclassified_pred_labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sift():\n",
    "    all_precision = []\n",
    "    all_recall = []\n",
    "    all_accuracy = []\n",
    "\n",
    "    misclassified_images = []\n",
    "    misclassified_true_labels = []\n",
    "    misclassified_pred_labels = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        training_set_person_i = x_train[i]\n",
    "        training_label_set_person_i = y_train[i]\n",
    "        testing_set_person_i = x_test[i]\n",
    "        testing_label_set_person_i = y_test[i]\n",
    "\n",
    "        _, train_desc = extract_sift_features(training_set_person_i)\n",
    "        descriptor_1 = train_desc[0]\n",
    "\n",
    "        test_desc_sift_features = extract_sift_features(testing_set_person_i)[1]\n",
    "        matches = [\n",
    "            compare_sift_features(descriptor_1, descriptor_2)[0]\n",
    "            for descriptor_2 in test_desc_sift_features\n",
    "        ]\n",
    "        predicted_labels = [\n",
    "            training_label_set_person_i[0] if match else \"Unknown\" for match in matches\n",
    "        ]\n",
    "\n",
    "        precision, recall, accuracy = calculate_metrics(\n",
    "            testing_label_set_person_i, predicted_labels\n",
    "        )\n",
    "\n",
    "        all_precision.append(precision)\n",
    "        all_recall.append(recall)\n",
    "        all_accuracy.append(accuracy)\n",
    "\n",
    "        (\n",
    "            misclassified_batch_images,\n",
    "            misclassified_batch_true_labels,\n",
    "            misclassified_batch_pred_labels,\n",
    "        ) = track_misclassifications(\n",
    "            testing_set_person_i, testing_label_set_person_i, predicted_labels\n",
    "        )\n",
    "\n",
    "        misclassified_images.extend(misclassified_batch_images)\n",
    "        misclassified_true_labels.extend(misclassified_batch_true_labels)\n",
    "        misclassified_pred_labels.extend(misclassified_batch_pred_labels)\n",
    "\n",
    "    return (all_precision, all_recall, all_accuracy), (\n",
    "        misclassified_images,\n",
    "        misclassified_true_labels,\n",
    "        misclassified_pred_labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_bovw, misclassified_bovw = eval_bovw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(\"Using BoVW with SIFT\", *metrics_bovw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_misclassifications(\"Using BoVW with SIFT\", *misclassified_bovw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_sift, misclassified_sift = eval_sift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(\"Vanilla SIFT\", *metrics_sift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_misclassifications(\"Vanilla SIFT\", *misclassified_sift)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
